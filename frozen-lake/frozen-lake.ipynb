{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=False)\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def policy_unif(s):\n",
    "  a = env.action_space.sample()\n",
    "  return a\n",
    "def best_policy(s):\n",
    "  policy_map = {\n",
    "    0: 1, 1: 2, 2: 1, 3: 0,\n",
    "    4: 1, 5: 1, 6: 1, 7: 2,\n",
    "    8: 2, 9: 2, 10: 1, 11: 2,\n",
    "    12: 1, 13: 2, 14: 2, 15: 2\n",
    "  }\n",
    "  return policy_map.get(s, env.action_space.sample())\n",
    "\n",
    "def best_policy_rand(s):\n",
    "  random_value = np.random.rand()\n",
    "  if random_value < 0.9:\n",
    "    return best_policy(s)\n",
    "  else:\n",
    "    return policy_unif(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "print(observation)\n",
    "print(reward)\n",
    "print(terminated)\n",
    "print(truncated)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectory(policy):\n",
    "  s0 = env.reset()[0]\n",
    "  traj_list = [s0]\n",
    "  while True:\n",
    "    a0 = policy(s0)\n",
    "    traj_list.append(a0)\n",
    "    s1, r0, terminated, truncated, _ = env.step(a0)\n",
    "    traj_list.append(r0)\n",
    "    traj_list.append(s1)\n",
    "    s0 = s1\n",
    "    if terminated or truncated:\n",
    "      break\n",
    "  return traj_list[:-1] #removing the terminal state\n",
    "\n",
    "def collect_trajectory_s_a(policy,s0,a0):\n",
    "  env.reset()\n",
    "  env.unwrapped.s = s0\n",
    "  traj_list = [s0,a0]\n",
    "  s1, r0, terminated, truncated, _ = env.step(a0)\n",
    "  traj_list.append(r0)\n",
    "  traj_list.append(s1)\n",
    "  s0=s1\n",
    "  if terminated or truncated:\n",
    "    return traj_list[:-1]\n",
    "  \n",
    "  while True:\n",
    "    a0 = policy(s0)\n",
    "    traj_list.append(a0)\n",
    "    s1, r0, terminated, truncated, _ = env.step(a0)\n",
    "    traj_list.append(r0)\n",
    "    traj_list.append(s1)\n",
    "    s0 = s1\n",
    "    if terminated or truncated:\n",
    "      break\n",
    "  return traj_list[:-1] #removing the terminal state\n",
    "\n",
    "def compute_return(traj,gamma=0.99):\n",
    "  if traj==[]:\n",
    "    return 0\n",
    "  else:\n",
    "    return traj[2]+gamma*compute_return(traj[3:],gamma)\n",
    "  \n",
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "def policy_evaluation(policy):\n",
    "    Q = np.zeros((n_states, n_actions))\n",
    "    for state in range(n_states):\n",
    "        for action in range(n_actions):\n",
    "            traj = collect_trajectory_s_a(policy, state, action)\n",
    "            Q[state, action] = compute_return(traj)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = collect_trajectory(best_policy_rand)\n",
    "print(traj)\n",
    "print(compute_return(traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = collect_trajectory_s_a(best_policy,14,1)\n",
    "print(traj)\n",
    "print(compute_return(traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_evaluation(best_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, r0, terminated, truncated, _ = env.step(2)\n",
    "print(s1)\n",
    "print(env.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
